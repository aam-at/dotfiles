# ---- llm ----
model: deepseek:deepseek-chat             # Specify the LLM to use
temperature: null                # Set default temperature parameter
top_p: null                      # Set default top-p parameter, range (0, 1)

# ---- behavior ----
save: true                       # Indicates whether to persist the message
keybindings: emacs               # Choose keybinding style (emacs, vi)
buffer_editor: null              # Command used to edit the current input with ctrl+o, env: EDITOR
wrap: no                         # Controls text wrapping (no, auto, <max-width>)
wrap_code: false                 # Enables or disables wrapping of code blocks

# ---- prelude ----
prelude: null                    # Set a default role or session to start with (e.g. role:<name>, session:<name>)
repl_prelude: null               # Overrides the `prelude` setting specifically for conversations started in REPL
agent_prelude: null              # Set a session to use when starting a agent. (e.g. temp, default)

# ---- session ----
# Controls the persistence of the session. if true, auto save; if false, not save; if null, asking the user
save_session: null
# Compress session when token count reaches or exceeds this threshold
compress_threshold: 4000
# Text prompt used for creating a concise summary of session message
summarize_prompt: 'Summarize the discussion briefly in 200 words or less to use as a prompt for future context.'
# Text prompt used for including the summary of the entire session
summary_prompt: 'This is a summary of the chat history as a recap: '

# ---- function-calling & agent ----
# Visit https://github.com/sigoden/llm-functions for setup instructions
function_calling: true           # Enables or disables function calling (Globally).
mapping_tools:                   # Alias for a tool or toolset
  # fs: 'fs_cat,fs_ls,fs_mkdir,fs_rm,fs_write'
use_tools: null                  # Which tools to use by default
# Per-Agent configuration
agents:
  - name: todo-sh
    model: null
    temperature: null
    top_p: null

clients:
  # See https://ollama.com/
  - type: ollama
    api_base: http://localhost:11434
    models:
      - name: gemma2:latest
        max_input_tokens: 8192
      - name: glm4:9b
        max_input_tokens: 131072
      - name: llama3
        max_input_tokens: 8192

  # See https://platform.deepseek.com/
  - type: openai-compatible
    name: deepseek
    api_base: https://api.deepseek.com/v1
    models:
    - name: deepseek-coder
      max_input_tokens: 128000
    - name: deepseek-chat
      max_input_tokens: 128000

  # See https://ai.google.dev/docs
  - type: gemini
    patches:
      '.*':
        chat_completions_body:
          safetySettings:
            - category: HARM_CATEGORY_HARASSMENT
              threshold: BLOCK_NONE
            - category: HARM_CATEGORY_HATE_SPEECH
              threshold: BLOCK_NONE
            - category: HARM_CATEGORY_SEXUALLY_EXPLICIT
              threshold: BLOCK_NONE
            - category: HARM_CATEGORY_DANGEROUS_CONTENT
              threshold: BLOCK_NONE
